name: AI Evaluation Suite

on:
  pull_request:
    branches: [main]
    paths:
      - 'functions/src/ai/**'
      - 'monitoring/eval-suite/**'
      - '.github/workflows/eval.yml'
  push:
    branches: [main]
  workflow_dispatch: # Manual trigger

jobs:
  evaluate:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: functions/pnpm-lock.yaml

      - name: Install dependencies
        working-directory: ./functions
        run: pnpm install --frozen-lockfile

      - name: Run evaluation suite
        working-directory: ./monitoring/eval-suite
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          npx ts-node eval-runner.ts

      - name: Check thresholds
        if: always()
        run: |
          echo "✅ Evaluation complete"
          echo "Thresholds:"
          echo "  - Accuracy: >85%"
          echo "  - P95 Latency: <500ms"
          echo "  - Urgency Precision: ≥90%"

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.sha }}
          path: monitoring/eval-suite/*.txt
          retention-days: 30

